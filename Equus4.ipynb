{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Equus4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRUZLCPXwaEqepwx9mxvJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mykon23/DL-2020Project/blob/split_eval_test/Equus4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wo1alGzRFMp",
        "colab_type": "text"
      },
      "source": [
        "Get the Equus Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6TB6FMiTb1x",
        "colab_type": "code",
        "outputId": "c71ddb63-7428-4646-ccb5-877f5c379bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "! wget -O Equus.tar.gz https://github.com/mykon23/DL-2020Project/blob/master/Equus.tar.gz?raw=true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-06 03:07:13--  https://github.com/mykon23/DL-2020Project/blob/master/Equus.tar.gz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/mykon23/DL-2020Project/raw/master/Equus.tar.gz [following]\n",
            "--2020-04-06 03:07:13--  https://github.com/mykon23/DL-2020Project/raw/master/Equus.tar.gz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mykon23/DL-2020Project/master/Equus.tar.gz [following]\n",
            "--2020-04-06 03:07:13--  https://raw.githubusercontent.com/mykon23/DL-2020Project/master/Equus.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18230746 (17M) [application/octet-stream]\n",
            "Saving to: ‘Equus.tar.gz’\n",
            "\n",
            "Equus.tar.gz        100%[===================>]  17.39M  54.8MB/s    in 0.3s    \n",
            "\n",
            "2020-04-06 03:07:14 (54.8 MB/s) - ‘Equus.tar.gz’ saved [18230746/18230746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ukhtYqTrqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -rf Equus\n",
        "! tar -zxf Equus.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6OXRtaBT29o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm *.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TzRW9faT7ql",
        "colab_type": "text"
      },
      "source": [
        "Create the Training Set, Validation Set, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVnkRBX1UCWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "dataset_dir = os.path.join('.', 'Equus')\n",
        "\n",
        "train_dir = os.path.join('.', 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "val_dir = os.path.join('.', 'validation')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "test_dir = os.path.join('.', 'test')\n",
        "os.mkdir(test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQDKc9yU4pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R97m7TfuYnuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Get a list of all the vailable images\n",
        "\n",
        "img_donkey = os.listdir( os.path.join(dataset_dir, 'Donkey'))\n",
        "img_horse = os.listdir(os.path.join(dataset_dir, 'Horse'))\n",
        "img_zebra = os.listdir(os.path.join(dataset_dir, 'Zebra'))\n",
        "print(f'Donkey {len(img_donkey)}')\n",
        "print(f'Horse {len(img_horse)}')\n",
        "print(f'Zebra {len(img_zebra)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pejxt-O-U8tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Create Training Directories\n",
        "train_donkey_dir = os.path.join(train_dir, 'Donkey')\n",
        "train_horse_dir = os.path.join(train_dir, 'Horse')\n",
        "train_zebra_dir = os.path.join(train_dir, 'Zebra')\n",
        "\n",
        "os.mkdir(train_donkey_dir)\n",
        "os.mkdir(train_horse_dir)\n",
        "os.mkdir(train_zebra_dir)\n",
        "\n",
        "##Create Validation Directories\n",
        "val_donkey_dir = os.path.join(val_dir, 'Donkey')\n",
        "val_horse_dir = os.path.join(val_dir, 'Horse')\n",
        "val_zebra_dir = os.path.join(val_dir, 'Zebra')\n",
        "\n",
        "os.mkdir(val_donkey_dir)\n",
        "os.mkdir(val_horse_dir)\n",
        "os.mkdir(val_zebra_dir)\n",
        "\n",
        "##Create Test Directories\n",
        "test_donkey_dir = os.path.join(test_dir, 'Donkey')\n",
        "test_horse_dir = os.path.join(test_dir, 'Horse')\n",
        "test_zebra_dir = os.path.join(test_dir, 'Zebra')\n",
        "\n",
        "os.mkdir(test_donkey_dir)\n",
        "os.mkdir(test_horse_dir)\n",
        "os.mkdir(test_zebra_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0xJ8qyRhoST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fjmai6VcDMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Keep the indices for the data splitting\n",
        "i_donkey = [0, 240, 315, 391]\n",
        "i_horse = [0, 185, 250, 314]\n",
        "i_zebra = [0, 185, 249, 339]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO_QsHIbhzsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Populate the Training Set\n",
        "for i in range(i_donkey[0], i_donkey[1]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Donkey'), img_donkey[i])\n",
        "  dst = os.path.join(train_donkey_dir, img_donkey[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_horse[0], i_horse[1]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Horse'), img_horse[i])\n",
        "  dst = os.path.join(train_horse_dir, img_horse[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_zebra[0], i_zebra[1]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Zebra'), img_zebra[i])\n",
        "  dst = os.path.join(train_zebra_dir, img_zebra[i])\n",
        "  shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7rqGEJ-lOw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Populate the Validation Set\n",
        "for i in range(i_donkey[1], i_donkey[2]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Donkey'), img_donkey[i])\n",
        "  dst = os.path.join(val_donkey_dir, img_donkey[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_horse[1], i_horse[2]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Horse'), img_horse[i])\n",
        "  dst = os.path.join(val_horse_dir, img_horse[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_zebra[1], i_zebra[2]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Zebra'), img_zebra[i])\n",
        "  dst = os.path.join(val_zebra_dir, img_zebra[i])\n",
        "  shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-q_ZflFlmOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Populate the Test Set\n",
        "for i in range(i_donkey[2], i_donkey[3]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Donkey'), img_donkey[i])\n",
        "  dst = os.path.join(test_donkey_dir, img_donkey[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_horse[2], i_horse[3]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Horse'), img_horse[i])\n",
        "  dst = os.path.join(test_horse_dir, img_horse[i])\n",
        "  shutil.copyfile(src, dst)\n",
        "\n",
        "for i in range(i_zebra[2], i_zebra[3]):\n",
        "  src = os.path.join(os.path.join(dataset_dir, 'Zebra'), img_zebra[i])\n",
        "  dst = os.path.join(test_zebra_dir, img_zebra[i])\n",
        "  shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hzjf9W_l_A-",
        "colab_type": "code",
        "outputId": "df4a3358-c0d7-495e-b674-22cd3789694a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "##Count the number of files within each directory\n",
        "! ls -lh train/*/* | wc -l\n",
        "! ls -lh validation/*/* | wc -l\n",
        "! ls -lh test/*/* | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610\n",
            "204\n",
            "230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHxwnxmHpzQu",
        "colab_type": "text"
      },
      "source": [
        "Build 2 Layer Variable Filter Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9TqrAFiqKeQ",
        "colab_type": "code",
        "outputId": "484ee8b9-20e8-493d-c60c-458df1faf949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "##Create Development Set Generators\n",
        "\n",
        "dat_generator = ImageDataGenerator(rescale=1./255)\n",
        "##Note that 61 * 10 = 610 training samples\n",
        "train_generator = dat_generator.flow_from_directory(train_dir, target_size=(256, 256), batch_size=10, class_mode='categorical')\n",
        "##Note that 17 * 12 = 240 validation samples\n",
        "val_generator = dat_generator.flow_from_directory(val_dir, target_size=(256, 256), batch_size=12, class_mode='categorical')\n",
        "\n",
        "##Create Test Generator\n",
        "##Note that 23 * 10 = 230 Test samples\n",
        "test_generator = dat_generator.flow_from_directory(test_dir, target_size=(256,256), batch_size=10, class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 610 images belonging to 3 classes.\n",
            "Found 204 images belonging to 3 classes.\n",
            "Found 230 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl8IiNiep4dB",
        "colab_type": "code",
        "outputId": "29a30384-7814-4569-a966-55e3605bdc1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Conv2D( 4, ( 3, 3 ), activation = 'relu', input_shape = (256, 256, 3) ) )\n",
        "model.add( Conv2D( 8, ( 3, 3 ), activation = 'relu' ) )\n",
        "model.add( Flatten() )\n",
        "model.add( Dense( 3, activation = 'softmax' ) )\n",
        "model.summary()\n",
        "\n",
        "##Compile the model\n",
        "model.compile( optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [ 'accuracy' ] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 254, 254, 4)       112       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 252, 252, 8)       296       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 508032)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1524099   \n",
            "=================================================================\n",
            "Total params: 1,524,507\n",
            "Trainable params: 1,524,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ur2htgxr-DU",
        "colab_type": "text"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzawBnkzsCLD",
        "colab_type": "code",
        "outputId": "2706a773-0856-4a56-cc76-3ecf1d22f7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "##Set the callback list\n",
        "callback_list = [ keras.callbacks.EarlyStopping(\n",
        "    monitor='val_acc',\n",
        "    patience=5,\n",
        ")]\n",
        "\n",
        "##Train the model\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=61,\n",
        "    epochs=20,\n",
        "    callbacks=callback_list,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=17)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "61/61 [==============================] - 29s 474ms/step - loss: 9.7061 - accuracy: 0.4311 - val_loss: 1.0322 - val_accuracy: 0.5931\n",
            "Epoch 2/20\n",
            "61/61 [==============================] - 29s 471ms/step - loss: 0.6103 - accuracy: 0.7869 - val_loss: 0.9768 - val_accuracy: 0.6373\n",
            "Epoch 3/20\n",
            " 5/61 [=>............................] - ETA: 18s - loss: 0.4268 - accuracy: 0.9200"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c30d2c59084c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m##callbacks=callback_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     validation_steps=17)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpdFKqqzu48w",
        "colab_type": "code",
        "outputId": "1f3e19d9-328b-4355-9bc1-5ee0ba8729b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "##Plot the learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "title = '2 Conv Layers 4 Filters Each'\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['acc'], 'bo', label='Training Acc')\n",
        "plt.plot(history.history['val_acc'], 'b', label='Validation Acc')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title(title)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], 'bo', label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], 'b', label='Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title(title)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7e9540638a31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPxHiKNZ0b3k",
        "colab_type": "code",
        "outputId": "929f22b2-1150-46b6-845d-6cff23cdab0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "##Observe the results of the model against the test data\n",
        "test_loss, test_acc = model.evaluate_generator(\n",
        "    test_generator,\n",
        "    steps=23\n",
        ")\n",
        "\n",
        "print(f'Test Acc: {test_acc}\\nTest Loss: {test_loss}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc: 0.591304361820221\n",
            "Test Loss: 2.160354088182035\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}